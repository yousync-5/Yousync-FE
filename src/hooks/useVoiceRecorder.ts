import { useRef, useState } from 'react';
import { useAudioStore } from '@/store/useAudioStore';

export function useVoiceRecorder() {
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const allBlobsRef = useRef<Record<number, Blob>>({});
  const [recording, setRecording] = useState(false);
  const {stream} = useAudioStore();
  
  // íƒ€ì´ë° ì¶”ì ì„ ìœ„í•œ ref
  const recordingStartTimeRef = useRef<number | null>(null);
  const recordingStopTimeRef = useRef<number | null>(null);
  
  // ìŠ¤í¬ë¦½íŠ¸ ì •ë³´ ì €ì¥ìš© ref
  const scriptInfoRef = useRef<{ startTime: number; endTime: number; scriptIndex: number } | null>(null);
  
  // ë™ì  ë³´ì •ê°’ ì €ì¥ìš© ref (ì‹¤ì œ ì¸¡ì •ëœ ì§€ì—°ë“¤ì˜ í‰ê· )
  const dynamicOffsetRef = useRef<number>(0.1); // ì´ˆê¸°ê°’ 100ms
  const measuredDelaysRef = useRef<number[]>([]); // ì¸¡ì •ëœ ì§€ì—°ë“¤

  // ì˜¤ë””ì˜¤ ê¸¸ì´ ë¶„ì„ ë° ìŠ¤í¬ë¦½íŠ¸ ì‹œê°„ê³¼ ë¹„êµ
  const analyzeRecordingTiming = async (blob: Blob, scriptIndex: number, stopDelay: number) => {
    try {
      // AudioContextë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì •
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const arrayBuffer = await blob.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      const actualDuration = audioBuffer.duration; // ì‹¤ì œ ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)
      const scriptInfo = scriptInfoRef.current;
      
      if (scriptInfo && scriptInfo.scriptIndex === scriptIndex) {
        const expectedDuration = scriptInfo.endTime - scriptInfo.startTime;
        const timeDifference = Math.abs(actualDuration - expectedDuration);
        const accuracyPercentage = ((1 - timeDifference / expectedDuration) * 100).toFixed(2);
        
        // íƒ€ì´ë° ì§€ì—° ë¶„ì„
        const recordingRequestTime = recordingStartTimeRef.current;
        const recordingStopTime = recordingStopTimeRef.current;
        const totalRecordingTime = recordingStopTime && recordingRequestTime 
          ? (recordingStopTime - recordingRequestTime) / 1000 
          : 0;
        
        console.log('ğŸµ === ë…¹ìŒ íƒ€ì´ë° ë¶„ì„ ===');
        console.log(`ğŸ“ ë¬¸ì¥ ${scriptIndex}:`);
        console.log(`   ìŠ¤í¬ë¦½íŠ¸ ì‹œê°„: ${scriptInfo.startTime}s ~ ${scriptInfo.endTime}s`);
        console.log(`   ì˜ˆìƒ ê¸¸ì´: ${expectedDuration.toFixed(3)}s`);
        console.log(`   ì‹¤ì œ ë…¹ìŒ ê¸¸ì´: ${actualDuration.toFixed(3)}s`);
        console.log(`   ì°¨ì´: ${timeDifference.toFixed(3)}s`);
        console.log(`   ì •í™•ë„: ${accuracyPercentage}%`);
        console.log(`   ì „ì²´ ë…¹ìŒ ì‹œê°„: ${totalRecordingTime.toFixed(3)}s`);
        console.log(`   MediaRecorder.stop() ì§€ì—°: ${stopDelay}ms`);
        
        // WAV íŒŒì¼ ìë¥´ê¸° (í›„ì²˜ë¦¬ ë°©ì‹)
        if (actualDuration > expectedDuration) {
          console.log('âœ‚ï¸  WAV íŒŒì¼ ìë¥´ê¸° ì‹œì‘...');
          const trimmedBlob = await trimAudioBlob(blob, expectedDuration, audioContext);
          
          // ìë¥¸ íŒŒì¼ë¡œ êµì²´
          allBlobsRef.current[scriptIndex] = trimmedBlob;
          
          // ìë¥¸ íŒŒì¼ì˜ ê¸¸ì´ í™•ì¸
          const trimmedArrayBuffer = await trimmedBlob.arrayBuffer();
          const trimmedAudioBuffer = await audioContext.decodeAudioData(trimmedArrayBuffer);
          const trimmedDuration = trimmedAudioBuffer.duration;
          
          console.log(`   ìë¥¸ í›„ ê¸¸ì´: ${trimmedDuration.toFixed(3)}s`);
          console.log(`   ìë¥´ê¸° í›„ ì°¨ì´: ${Math.abs(trimmedDuration - expectedDuration).toFixed(3)}s`);
          
          if (Math.abs(trimmedDuration - expectedDuration) < 0.1) {
            console.log('âœ… WAV íŒŒì¼ ìë¥´ê¸° ì„±ê³µ!');
          } else {
            console.warn('âš ï¸  WAV íŒŒì¼ ìë¥´ê¸° í›„ì—ë„ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.');
          }
          
          audioContext.close();
        } else {
          console.log('âœ… ë…¹ìŒ ê¸¸ì´ê°€ ì •í™•í•©ë‹ˆë‹¤. ìë¥´ê¸° ë¶ˆí•„ìš”.');
          audioContext.close();
        }
        
        // ì§€ì—° ì›ì¸ ë¶„ì„
        if (timeDifference > 0.1) {
          console.log('ğŸ” ì§€ì—° ì›ì¸ ë¶„ì„:');
          if (actualDuration > expectedDuration) {
            console.log(`   - MediaRecorder.stop() ì§€ì—°: ${stopDelay}ms`);
            console.log(`   - ì´ˆê³¼ ë…¹ìŒ: ${(actualDuration - expectedDuration).toFixed(3)}s`);
            console.log(`   - í›„ì²˜ë¦¬ë¡œ ì •í™•í•œ ê¸¸ì´ë¡œ ìë¥´ê¸° ì™„ë£Œ`);
          } else {
            console.log(`   - ë…¹ìŒì´ ì˜ˆìƒë³´ë‹¤ ì§§ìŒ (ì¡°ê¸° ì¢…ë£Œ ê°€ëŠ¥ì„±)`);
          }
        }
        
        if (timeDifference > 0.5) {
          console.warn(`âš ï¸  íƒ€ì´ë° ì°¨ì´ê°€ í½ë‹ˆë‹¤! (${timeDifference.toFixed(3)}s)`);
        } else if (timeDifference > 0.2) {
          console.log(`âš ï¸  íƒ€ì´ë° ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤. (${timeDifference.toFixed(3)}s)`);
        } else {
          console.log(`âœ… íƒ€ì´ë°ì´ ì •í™•í•©ë‹ˆë‹¤! (ì°¨ì´: ${timeDifference.toFixed(3)}s)`);
        }
        console.log('========================');
      }
      
    } catch (error) {
      console.error('[ERROR] ì˜¤ë””ì˜¤ ê¸¸ì´ ë¶„ì„ ì‹¤íŒ¨:', error);
    }
  };

  // WAV íŒŒì¼ ìë¥´ê¸° í•¨ìˆ˜
  const trimAudioBlob = async (blob: Blob, targetDuration: number, audioContext: AudioContext): Promise<Blob> => {
    try {
      const arrayBuffer = await blob.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      // ëª©í‘œ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
      const targetSamples = Math.floor(targetDuration * audioBuffer.sampleRate);
      
      // ì•ì—ì„œ ìë¥¼ ìƒ˜í”Œ ìˆ˜ ê³„ì‚° (ì´ˆê³¼ë¶„ - 0.2ì´ˆ)
      const actualDuration = audioBuffer.duration;
      let startOffsetSamples = 0;
      if (actualDuration > targetDuration) {
        const excess = actualDuration - targetDuration;
        startOffsetSamples = Math.max(0, Math.floor((excess - 0.2) * audioBuffer.sampleRate));
      }

      // ìƒˆë¡œìš´ AudioBuffer ìƒì„± (ëª©í‘œ ê¸¸ì´ë§Œí¼)
      const trimmedBuffer = audioContext.createBuffer(
        audioBuffer.numberOfChannels,
        targetSamples,
        audioBuffer.sampleRate
      );

      // ê° ì±„ë„ì˜ ë°ì´í„°ë¥¼ ë³µì‚¬ (ì•ì—ì„œ ìë¥´ê¸°)
      for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
        const originalData = audioBuffer.getChannelData(channel);
        const trimmedData = trimmedBuffer.getChannelData(channel);
        for (let i = 0; i < targetSamples; i++) {
          trimmedData[i] = originalData[startOffsetSamples + i] || 0;
        }
      }

      // AudioBufferë¥¼ Blobìœ¼ë¡œ ë³€í™˜
      const trimmedBlob = await audioBufferToBlob(trimmedBuffer);
      return trimmedBlob;
    } catch (error) {
      console.error('[ERROR] WAV íŒŒì¼ ìë¥´ê¸° ì‹¤íŒ¨:', error);
      return blob; // ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
    }
  };

  // AudioBufferë¥¼ Blobìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
  const audioBufferToBlob = async (audioBuffer: AudioBuffer): Promise<Blob> => {
    // ê°„ë‹¨í•œ WAV ì¸ì½”ë”© (ê¸°ì¡´ encodeWav í•¨ìˆ˜ í™œìš©)
    const { encodeWav } = await import('@/utils/encodeWav');
    return encodeWav(audioBuffer);
  };

  const startRecording = async (scriptIndex: number, startTime: number, endTime: number) => {
    // const stream = await navigator.mediaDevices.getUserMedia({ audio: true }); // ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­
    if(!stream){
      console.warn("Stream not initialized");
      return;
    }
    
    // ìŠ¤í¬ë¦½íŠ¸ ì •ë³´ ì €ì¥
    scriptInfoRef.current = { startTime, endTime, scriptIndex };
    
    // ë…¹ìŒ ì‹œì‘ ì‹œê°„ ê¸°ë¡
    recordingStartTimeRef.current = Date.now();
    console.log(`[TIMING] ë…¹ìŒ ì‹œì‘ ìš”ì²­: ${new Date(recordingStartTimeRef.current).toISOString()}`);
    console.log(`[SCRIPT] ë¬¸ì¥ ${scriptIndex}: ${startTime}s ~ ${endTime}s (ì˜ˆìƒ ê¸¸ì´: ${endTime - startTime}s)`);
    console.log(`[OFFSET] í˜„ì¬ ë™ì  ë³´ì •ê°’: ${dynamicOffsetRef.current.toFixed(3)}s`);
    
    const supportsOpus = MediaRecorder.isTypeSupported('audio/webm;codecs=opus');
    const supportsMp4 = MediaRecorder.isTypeSupported('audio/mp4');

    // ìµœì ì˜ ì„¤ì • ì„ íƒ
    const recorderOptions = supportsOpus
      ? { mimeType: 'audio/webm;codecs=opus', audioBitsPerSecond: 320000 }
      : supportsMp4
        ? { mimeType: 'audio/mp4', audioBitsPerSecond: 320000 }
        : { audioBitsPerSecond: 320000 };  // ê¸°ë³¸ ì„¤ì •

    console.log(`[RECORDER] ì‚¬ìš© ì¤‘ì¸ ë…¹ìŒ ì„¤ì •:`, recorderOptions);
    const recorder = new MediaRecorder(stream, recorderOptions);

    mediaRecorderRef.current = recorder;  // ì´í›„ì— ì¤‘ì§€ ê°™ì€ ì‘ì—…ì— ì“¸ ìˆ˜ ìˆìŒ.
    chunksRef.current = []; // ë…¹ìŒëœ ë°ì´í„° ë‹´ì„ ë°°ì—´(chunks)ì„ ì´ˆê¸°í™”

    recorder.ondataavailable = (e) => {// ë…¹ìŒ ì¤‘ ì¼ì • ì£¼ê¸°ë§ˆë‹¤ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ e.data í˜•íƒœë¡œ ì „ë‹¬
      chunksRef.current.push(e.data); //chunkRef.current ë°°ì—´ì— ìˆœì„œëŒ€ë¡œ ì €ì¥
    };

    recorder.start(); // ë…¹ìŒ ì‹œì‘
    console.log('ë…¹ìŒ ì‹œì‘');
    setRecording(true); // í˜„ì¬ ë…¹ìŒ ì¤‘ì´ë¼ëŠ” ìƒíƒœë¥¼ trueë¡œ
  };

  // Blob(ë…¹ìŒëœ ì˜¤ë””ì˜¤)ë¥¼ Promiseë¡œ ë°˜í™˜, ë…¹ìŒì´ ì•ˆëœ ê²½ìš°ì—ëŠ” null ë°˜í™˜
  const stopRecording = async (idx: number): Promise<Blob | null> => {
    console.log('[DEBUG] stopRecording called', idx);
    if (mediaRecorderRef.current) {
      console.log('[DEBUG] mediaRecorderRef.current.state:', mediaRecorderRef.current.state);
    } else {
      console.warn('[DEBUG] mediaRecorderRef.current is null');
    }
    return new Promise((resolve) => {
      if (!mediaRecorderRef.current) {
        console.warn('[WARN] stopRecording: mediaRecorderRef.current is null');
        setRecording(false);
        console.log('[DEBUG] stopRecording resolve(null) - mediaRecorderRef.current is null');
        return resolve(null);
      }
      mediaRecorderRef.current.onstop = async () => {
        console.log('[DEBUG] mediaRecorderRef.current.onstop fired');
        try {
          const blob = new Blob(chunksRef.current, { type: 'audio/wav' });
          allBlobsRef.current[idx] = blob;
          console.log('[DEBUG] Blob ìƒì„±ë¨', blob);
          
          // ë…¹ìŒ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
          recordingStopTimeRef.current = Date.now();
          const stopDelay = recordingStopTimeRef.current - recordingStartTimeRef.current!;
          
          // ë…¹ìŒ íƒ€ì´ë° ë¶„ì„ ì‹¤í–‰
          await analyzeRecordingTiming(blob, idx, stopDelay);

          // ğŸ”½ ì‹¤ì œ ì„œë²„ë¡œ ë³´ë‚¼ Blobì˜ ê¸¸ì´(ì´ˆ) ì½˜ì†” ì¶œë ¥
          const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
          const arrayBuffer = await allBlobsRef.current[idx].arrayBuffer();
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
          console.log(`ğŸš€ [ì—…ë¡œë“œ ì „] ìµœì¢… Blob ê¸¸ì´: ${audioBuffer.duration.toFixed(3)}s (ë¬¸ì¥ ${idx})`);
          audioContext.close();
          
          resolve(allBlobsRef.current[idx]);
          setRecording(false);
          // ì—¬ê¸°ì„œ wavíŒŒì¼ë¡œ ë³€í™˜í•´ì•¼
          console.log('[DEBUG] setRecording(false) called in onstop');
        } catch (e) {
          console.error('[ERROR] onstop handler failed', e);
          setRecording(false);
          console.log('[DEBUG] stopRecording resolve(null) - onstop handler failed');
          resolve(null);
        }
      };
      try {
        mediaRecorderRef.current.stop();
        console.log('[DEBUG] mediaRecorderRef.current.stop() called');
      } catch (e) {
        console.error('[ERROR] mediaRecorderRef.current.stop() threw', e);
        setRecording(false);
        console.log('[DEBUG] stopRecording resolve(null) - stop() threw');
        resolve(null);
      }
      setTimeout(() => {
        if (recording) {
          console.warn('[WARN] stopRecording: onstop not called in 1s, forcing setRecording(false)');
          setRecording(false);
          console.log('[DEBUG] stopRecording resolve(null) - onstop timeout');
          resolve(null);
        }
      }, 1000);
    });
  };

  return {
    startRecording,
    stopRecording,
    recording,
    getAllBlobs: () => allBlobsRef.current,  // Record<number, Blob> í˜•íƒœë¡œ ë°˜í™˜
  };
}